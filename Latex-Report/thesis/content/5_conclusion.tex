\chapter{Conclusion and Future Work}
\label{ch5_conclusion}
\section{Conclusion}
\label{6_1}
This report discussed the hardware acceleration by leveraging power-efficient heterogeneous architectures, namely GPUs and FPGAs by threaded programming (OpenCL) and high level synthesis. As the optimization objective was improving execution time, several compiler optimizations and platform-specific optimizations were used to inspect the gain in runtime. This report covered the study of two trending compute-intensive applications, isolation of software hot-spots, design decisions and improved implementation using heterogeneous hardware platform. Our experiments with MNIST digit classifier revealed that when the sequential C++ code is translated to parallel threads spawned together for concurrent execution, the speed-up is significant (as high as -- from our experiments). A huge dataset comprising of 10000 images was classified in a few microseconds. It also reveaved that any OpenCL compliant device, CPU or GPU, can offer acceleration depending on the number of low power cores available in the platform and also the memory access model. Hence, understanding of all the OpenCL models is crucial to schedule the work suitably among different compute units. The study of Fully Homomorphic Encryption scheme revealed that domain expertise is also a key factor to achieve hardware acceleration, in addition to accelerator-awareness. All computations performed in FHE are on ring lattices and hence, offloading the entire Bootstrapping logic onto hardware requires sound mathematical background on lattice-based computations. We noticed a gain of -- upon offloading the FFT to Zedboard. With high-end boards such as Virtex 7, a much higher speed-up can be accomplished and unrolling factor also increased, due to availability of more resources. The key challenge in hardware acceleration is ensuring that functionality is preserved upon offloading to an accelerator. High-speed Streaming DMA Transfers from high performance ports of Zynq Processing system to Programmable logic via AXI Interface assure that the communication overhead is less.
Explore assembly language FFT Libraries and study the speed-up.

\section{Future Work}
With the current choice of FPGA, a maximum of 2 FFT blocks can run in a single target board. Future works could incorporate:
\begin{itemize}
\item Identifying a novel way to \textbf{fit in a single AddToAccumulator block onto a single board}: \\The challenge in doing so is that each ciphertext comprises of an n-dimensional array (a[n]; n = 500) and an integer modulus b. Computations on ciphertexts take up alot of area and hence, these dimensions have to be intuitively handled.
\item \textbf{Reuse of the hardware FFT blocks in the new TFHE Library} implemented in April, 2017, to verify the generality of the implementation. As TFHE library already promises bootstrapping speed of less than 0.1 seconds, the gain in hardware for bootstrapping can be studied by porting specific "hot" functions to the hardware.
\item \textbf{Runtime analysis on coarse-grained and fine-grained Overlay Architectures} with efficient interfacing between host processor, DSP Units and other high-speed vector engines.
\end{itemize}