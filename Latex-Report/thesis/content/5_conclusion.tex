\chapter{Conclusion and Future Work}
\label{ch5_conclusion}
\section{Conclusion}
\label{6_1}
This report discussed hardware acceleration using heterogeneous architectures, specifically GPUs and FPGAs by means of threaded programming (OpenCL) and high level synthesis. As the optimization objective was improving execution time, several compiler and platform-specific optimizations were used to inspect the gain in runtime. This report covered the study of two trending compute-intensive applications, isolation of software hot-spots, design decisions and improved implementation using heterogeneous hardware platform. \newline \newline Our experiments with MNIST digit classifier revealed that when the sequential C++ code is translated to parallel threads spawned together for concurrent execution, the speed-up is significant (1.3 ms in quad-core CPU and 16 ms in dual-core GPU instead of 77 ms in sequential flow). A huge dataset comprising of 10000 images was classified in a few microseconds. It also revealed that any OpenCL compliant device, CPU or GPU, can offer acceleration depending on the number of low power cores available in the platform and also the memory access model. Hence, understanding of all the OpenCL models is crucial to schedule the work suitably among different compute units. The study of Fully Homomorphic Encryption scheme revealed that domain expertise is also a key factor to achieve hardware acceleration, in addition to accelerator-awareness. All computations performed in FHE are on ring lattices and hence, offloading the entire Bootstrapping logic onto hardware requires sound mathematical background on lattice-based computations. We noticed a speedup of 32 \% ($\frac{9.95}{30.89}$ $\times$ 100) upon offloading the FFT to Zedboard. With high-end boards such as Virtex 7, a much higher speed-up can be accomplished and unrolling factor also increased, due to availability of more resources. The key challenge in hardware acceleration is ensuring that functionality is preserved upon offloading to an accelerator. 
\section{Future Work}
With the current choice of FPGA, a maximum of 2 FFT blocks can run in a single target board. Future works could incorporate:
\begin{itemize}
\item Identifying a novel way to \textbf{fit in a single AddToAccumulator block onto a single board}: \\The challenge in doing so is the huge dimensionality involved (Section \ref{4_1_3_1}). Computations on ciphertexts take up alot of area and hence, these dimensions have to be intuitively handled.
\item \textbf{Reuse of the hardware FFT blocks in the new TFHE Library} implemented in April, 2017, to verify the generality of the implementation. As TFHE library already promises bootstrapping speed of less than 0.1 seconds, the gain in hardware for bootstrapping can be studied by porting specific "hot" functions to the hardware.
\item \textbf{Runtime analysis on coarse-grained and fine-grained Overlay Architectures} with efficient interfacing between host processor, DSP Units and other high-speed vector engines.
\end{itemize}