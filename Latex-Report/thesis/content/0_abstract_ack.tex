\chapter*{Abstract} 
\label{ch0i_Abstract}
\quad With the advancements in technology, parallel processing platforms such as graphics processing units (GPUs), massively parallel processor arrays (MPPAs) and multi-core processors are gaining popularity for accelerated execution of compute-intensive applications. However the performance gains achieved by adding more cores inside a computing platform come at the cost of rapidly scaling complexities to the inter-core communication, memory coherency and, most importantly, the power consumption. Increasing the operating frequency or the number of cores does not yield the performance desired for the current complex, compute-intensive applications. This calls for multi-core systems that achieve the desired performance by integrating specialized processing abilities required for specific tasks which require extensive analysis of the application and the performance demands of the application. For example, the performance demand for first convolution layer in MNIST digit classifier is 300 million multiply-accumulate (MAC) operations per second for sub-millisecond latency which can go up to 300 billion MAC/s for sub-microsecond latency. 
\newline This report intends to investigate two compute-intensive applications, namely MNIST Digit classifier using Convolutional Neural Network (CNN), and Fully Homomorphic Encryption (FHE). For MNIST-CNN, we observe the performance of 24 million MAC/s on Intel i3 running at 2.3 GHz using a single-threaded C++ code which can go up to 1.5 billion MAC/s using OpenCL on the same platform. To achieve sub-microsecond latency, 20 convolution engines (running at 600 MHz) can be used where each engine is able to produce one pixel by performing 25 MAC operations every clock cycle. The peak performance of such a hypothetical engine is 300 billion MAC/sec. We also present similar analysis for second application (FHE). Apart from the theoretical analysis, we also present experiments to characterize the performance of different hardware architectures for CNN and FHE.

\chapter*{Acknowledgment} 
\label{ch0ii_Acknowledgement}

\quad Firstly, I would like to extend my deepest gratitude to my supervisor, Assoc Prof Dr.Douglas Leslie Maskell for giving me an opportunity to work on my area of interest. His deep insight in the field, enthusiastic support and invaluable suggestions helped me progress through my project work. \newline

I am also grateful for the effective knowledge sharing sessions Iâ€™ve had with my mentor, Mr.Abhishek Kumar Jain, a PhD student under Dr.Douglas Maskell. His patient reviews, constructive feedback, constant encouragement and timely help steered me in the right direction and helped finish my thesis on time.\newline 

I am greatly indebted to Mr.Gopalakrishna Hegde, a former research assistant at NTU, for his inputs and assistance during the first phase of the project. Special thanks to Mr.Prashant Ravi, a former M.Sc. student under Prof Douglas, who helped me understand the rudiments of the project field during the project exploration phase, gave warm-up exercises for me to get a hang of the work ahead and eased the tool setup.\newline 

My sincere thanks to Mr.Jeremiah Chua from the Hardware and Embedded Systems Lab (HESL) for the lab facilities and technical support.\newline 

Last but not the least, I would like to thank my family for their prayers and support in my pursuit of higher education. 